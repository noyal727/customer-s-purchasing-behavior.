{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Replicating Models from Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import e\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import gamma\n",
    "from scipy.optimize import minimize\n",
    "from math import e\n",
    "from math import factorial\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: The Poisson Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the example related to billboard exposures from class. The associated data is in the file billboard.csv. Write code to estimate the parameters of the Poisson model using maximum likelihood estimation (MLE).Report your code, the estimated parameters and the maximum value of the log-likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('billboard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXPOSURES</th>\n",
       "      <th>PEOPLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXPOSURES  PEOPLE\n",
       "0          0      48\n",
       "1          1      37\n",
       "2          2      30\n",
       "3          3      24\n",
       "4          4      20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPEOPLE\u001b[39m\u001b[38;5;124m'\u001b[39m]]) \u001b[38;5;66;03m#define the first array that will go through the PLL function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEXPOSURES\u001b[39m\u001b[38;5;124m'\u001b[39m]]) \u001b[38;5;66;03m#define the second array that will go through PLL\u001b[39;00m\n\u001b[1;32m      3\u001b[0m lmbda \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "a = np.array(df[['PEOPLE']]) #define the first array that will go through the PLL function\n",
    "b = np.array(df[['EXPOSURES']]) #define the second array that will go through PLL\n",
    "lmbda = 1\n",
    "\n",
    "def PLL(lmbda,a,b):\n",
    "    c = 0 #we create a variable that will store the cummulative sum of the iteration below\n",
    "    for i in range(len(a)): #this will go through through the dataset rows\n",
    "        c += a[i]*np.log(poisson.pmf(b[i], lmbda)) #we get the sum of PEOPLE[i]*LN(POISSON(EXPOSURES[i],lambda))\n",
    "    return (-1)*c #we need the non-negative cummulative result\n",
    "\n",
    "soln = minimize(\n",
    "    PLL,\n",
    "    args = (a,b),\n",
    "    x0 = np.array((1)),\n",
    "    bounds=[(0.000001,None)],\n",
    "    tol=1e-10,\n",
    "    options={'ftol' : 1e-8},\n",
    ")\n",
    "final_lmbda = soln.x[0]\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    c += a[i]*np.log(poisson.pmf(b[i],final_lmbda))\n",
    "\n",
    "print(\"Lambda:{}\".format(final_lmbda))\n",
    "print(\"MAX_LL:{}\".format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: The NBD Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, write code (for the same dataset) to estimate the parameters of the NBD model using MLE. Report your code, the estimated parameters and the maximum value of the log-likelihood. Evaluate the NBD model vis-a-vis the Poisson model; explain which is better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXPOSURES</th>\n",
       "      <th>PEOPLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EXPOSURES  PEOPLE\n",
       "0           0      48\n",
       "1           1      37\n",
       "2           2      30\n",
       "3           3      24\n",
       "4           4      20\n",
       "5           5      16\n",
       "6           6      13\n",
       "7           7      11\n",
       "8           8       9\n",
       "9           9       7\n",
       "10         10       6\n",
       "11         11       5\n",
       "12         12       5\n",
       "13         13       3\n",
       "14         14       3\n",
       "15         15       2\n",
       "16         16       2\n",
       "17         17       2\n",
       "18         18       1\n",
       "19         19       1\n",
       "20         20       2\n",
       "21         21       1\n",
       "22         22       1\n",
       "23         23       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('billboard.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.21751778150917153\n",
      "n:0.9692594289057651\n",
      "Log likelihood:[-649.68882748]\n"
     ]
    }
   ],
   "source": [
    "def NBD(params,k,t):\n",
    "    alpha,n = params\n",
    "    if k==0:\n",
    "        return (alpha/(alpha+t))**n\n",
    "    else:\n",
    "        return (((n+k-1)*t)/(k*(alpha+t)))*NBD(params,k-1,t)\n",
    "\n",
    "\n",
    "def NBDLL(params,t,a,b):\n",
    "    nbd = 0\n",
    "    for i in range(len(a)):\n",
    "        nbd += a[i]*np.log(NBD(params,b[i],t))\n",
    "    return (-1)*nbd\n",
    "\n",
    "alpha = 1\n",
    "n = 1\n",
    "t = 1\n",
    "solnbd = minimize(\n",
    "    NBDLL,\n",
    "    args = (t,a,b),\n",
    "    x0 = np.array((1,1)),\n",
    "    bounds=[(0.000001,None),(0.000001,None)],\n",
    "    tol=1e-10,\n",
    "    options={'ftol' : 1e-8},\n",
    ")\n",
    "alpha = solnbd.x[0]\n",
    "n = solnbd.x[1]\n",
    "nbd = 0\n",
    "params = (alpha,n)\n",
    "for i in range(len(a)):\n",
    "    nbd += a[i]*np.log(NBD(params,b[i],t))\n",
    "print(\"Alpha:{}\".format(alpha))\n",
    "print(\"n:{}\".format(n))\n",
    "print(\"Log likelihood:{}\".format(nbd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: The Poisson Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now consider the khakichinos.com example from class; The associated data is in the file khakichinos.csv.Estimate all relevant parameters for Poisson regression using MLE. Report your code, the estimated parameters and the maximum value of the log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('khakichinos.csv')\n",
    "a=np.array(df[['LnInc']])\n",
    "b=np.array(df[['Sex']])\n",
    "c=np.array(df[['LnAge']])\n",
    "d=np.array(df[['HHSize']])\n",
    "k=np.array(df[['NumberofVisits']])\n",
    "\n",
    "def PR(params,a,b,c,d,k):\n",
    "    lmbda0, beta1, beta2, beta3, beta4 = params\n",
    "    p = 0\n",
    "    pt1 = 0\n",
    "    pt2 = 0\n",
    "    pt3 = 0\n",
    "    for i in range(len(a)):\n",
    "        lmbda= lmbda0*math.exp(beta1*a[i]+beta2*b[i]+beta3*c[i]+beta4*d[i])\n",
    "        fact = float(math.factorial(float(k[i])))\n",
    "        pt1 = pt1 + k[i]*np.log(lmbda)\n",
    "        pt2 = pt2 + lmbda\n",
    "        pt3 = pt3 + np.log(fact)\n",
    "    p = pt1-pt2-pt3\n",
    "    return (-1)*p\n",
    "\n",
    "#calculate exponent 1st\n",
    "#try not to multiply things together\n",
    "#take log of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6291.4967508])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECKING THAT OUR FUNCTION WORKS\n",
    "lmbda0=0.0439\n",
    "beta1=0.0938\n",
    "beta2=0.0043\n",
    "beta3=0.5882\n",
    "beta4=-0.0359\n",
    "params=(lmbda0,beta1,beta2,beta3,beta4)\n",
    "test=PR(params,a,b,c,d,k)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda0=1\n",
    "beta1=1\n",
    "beta2=1\n",
    "beta3=1\n",
    "beta4=1\n",
    "params=lmbda0,beta1,beta2,beta3,beta4\n",
    "soln = minimize(\n",
    "    PR,\n",
    "    args = (a,b,c,d,k),\n",
    "    x0 = np.array((1,1,1,1,1)),\n",
    "    bounds=[(0.00001, None), (None,None), (None,None), (None,None), (None,None)],\n",
    "    tol=1e-10,\n",
    "    options={'ftol' : 1e-8},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda0: 0.04376650692216292\n",
      "Beta1: 0.09426526605833353\n",
      "Beta2: 0.004909204441529336\n",
      "Beta3: 0.5878466719036146\n",
      "Beta4: -0.03625361512373587\n",
      "Log Likelihood: [-6291.49715362]\n"
     ]
    }
   ],
   "source": [
    "pt1=0\n",
    "pt2=0\n",
    "pt3=0\n",
    "\n",
    "lmbda0 = soln.x[0]\n",
    "beta1=soln.x[1]\n",
    "beta2=soln.x[2]\n",
    "beta3=soln.x[3]\n",
    "beta4=soln.x[4]\n",
    "params = (lmbda0, beta1, beta2, beta3, beta4)\n",
    "for i in range(len(a)):\n",
    "    lmbda= lmbda0*math.exp(beta1*a[i]+beta2*b[i]+beta3*c[i]+beta4*d[i])\n",
    "    fact = float(math.factorial(float(k[i])))\n",
    "    pt1 = pt1 + k[i]*np.log(lmbda)\n",
    "    pt2 = pt2 + lmbda\n",
    "    pt3 = pt3 + np.log(fact)\n",
    "p = pt1-pt2-pt3\n",
    "print(\"Lambda0: {}\".format(lmbda0))\n",
    "print(\"Beta1: {}\".format(beta1))\n",
    "print(\"Beta2: {}\".format(beta2))\n",
    "print(\"Beta3: {}\".format(beta3))\n",
    "print(\"Beta4: {}\".format(beta4))\n",
    "print(\"Log Likelihood: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: The NBD Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the khakichinos.com example again. Estimate all relevant parameters for NBD Regression using MLE. Report your code, the estimated parameters and the maximum value of the log-likelihood. Evaluate the NBD regression vis-a-vis the Poisson regression; explain which is better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NumberofVisits</th>\n",
       "      <th>LnInc</th>\n",
       "      <th>Sex</th>\n",
       "      <th>LnAge</th>\n",
       "      <th>HHSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.379394</td>\n",
       "      <td>1</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9.769956</td>\n",
       "      <td>1</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>0</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10.915088</td>\n",
       "      <td>1</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10.915088</td>\n",
       "      <td>1</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>2724</td>\n",
       "      <td>0</td>\n",
       "      <td>9.528794</td>\n",
       "      <td>1</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>2725</td>\n",
       "      <td>0</td>\n",
       "      <td>11.379394</td>\n",
       "      <td>0</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>2726</td>\n",
       "      <td>0</td>\n",
       "      <td>11.191342</td>\n",
       "      <td>1</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>2727</td>\n",
       "      <td>0</td>\n",
       "      <td>10.532096</td>\n",
       "      <td>1</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>2728</td>\n",
       "      <td>0</td>\n",
       "      <td>11.736069</td>\n",
       "      <td>1</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2728 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  NumberofVisits      LnInc  Sex     LnAge  HHSize\n",
       "0        1               0  11.379394    1  3.871201       2\n",
       "1        2               5   9.769956    1  4.043051       1\n",
       "2        3               0  11.082143    0  3.332205       2\n",
       "3        4               0  10.915088    1  3.951244       3\n",
       "4        5               0  10.915088    1  2.833213       3\n",
       "...    ...             ...        ...  ...       ...     ...\n",
       "2723  2724               0   9.528794    1  2.944439       2\n",
       "2724  2725               0  11.379394    0  3.970292       2\n",
       "2725  2726               0  11.191342    1  3.044522       3\n",
       "2726  2727               0  10.532096    1  2.890372       4\n",
       "2727  2728               0  11.736069    1  2.833213       3\n",
       "\n",
       "[2728 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k=pd.read_csv('khakichinos.csv')\n",
    "df_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINING THE EQUATION FOR AN NBD REGRESSION BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2888.9661141906977"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('khakichinos.csv')\n",
    "a=np.array(df[['LnInc']])\n",
    "b=np.array(df[['Sex']])\n",
    "c=np.array(df[['LnAge']])\n",
    "d=np.array(df[['HHSize']])\n",
    "k=np.array(df[['NumberofVisits']])\n",
    "\n",
    "def NBDR(params,a,b,c,d,k):\n",
    "    alpha, n, beta1, beta2, beta3, beta4 = params\n",
    "    p = 0#we create a variable that will store the cummulative sum of the iteration below\n",
    "    pt1 = 0\n",
    "    pt2 = 0\n",
    "    pt3 = 0\n",
    "    for i in range(len(a)):\n",
    "        pt1 = float(math.gamma(n+k[i]))/(float(math.gamma(n))*float(math.factorial(int(k[i]))))\n",
    "        pt2 = (alpha/(alpha+math.exp(beta1*a[i]+beta2*b[i]+beta3*c[i]+beta4*d[i])))**n\n",
    "        pt3 = (e**(beta1*a[i]+beta2*b[i]+beta3*c[i]+beta4*d[i])/(alpha+float((e**(beta1*a[i]+beta2*b[i]+beta3*c[i]+beta4*d[i])))))**k[i]\n",
    "        p = p + np.log(pt1*pt2*pt3)\n",
    "    return (-1)*float(p[0]) #we'll need the negative so we can use \n",
    "alpha=8.192937559\n",
    "n=0.138751195\n",
    "beta1 =0.07338418\n",
    "beta2 =-0.009304959\n",
    "beta3 = 0.90208107\n",
    "beta4 = -0.02433638\n",
    "params = (alpha, n, beta1, beta2, beta3, beta4)\n",
    "NBDR(params,a,b,c,d,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-8d93c84141b2>:18: RuntimeWarning: invalid value encountered in log\n",
      "  p = p + np.log(pt1*pt2*pt3)\n",
      "<ipython-input-13-8d93c84141b2>:18: RuntimeWarning: divide by zero encountered in log\n",
      "  p = p + np.log(pt1*pt2*pt3)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-adcf8ca3dbf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbeta4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m solnbdr = minimize(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mNBDR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    615\u001b[0m                                   **options)\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    618\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-8d93c84141b2>\u001b[0m in \u001b[0;36mNBDR\u001b[0;34m(params, a, b, c, d, k)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbeta3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbeta4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbeta3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbeta4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbeta3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbeta4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "alpha=1\n",
    "n=1\n",
    "beta1=1\n",
    "beta2=1\n",
    "beta3=1\n",
    "beta4=1\n",
    "params=(n, beta1, beta2, beta3, beta4, alpha)\n",
    "solnbdr = minimize(\n",
    "    NBDR,\n",
    "    args = (a,b,c,d,k),\n",
    "    x0 = np.array((1,1,1,1,1,1)),\n",
    "    bounds=[(0.000001,None),(None,None),(None,None),(None,None),(None,None),(None,None)],\n",
    "    tol=1e-10,\n",
    "    options={'ftol' : 1e-8},\n",
    ")\n",
    "\n",
    "# alpha = solnbdr.x[0]\n",
    "# n = solnbdr.x[1]\n",
    "# p = 0\n",
    "\n",
    "# params = (alpha,n,beta1,beta2,beta3)\n",
    "# for i in range(len(a)): #this will go through through the dataset rows. \n",
    "#     pt1 = float(math.gamma(n+k[i]))/(float(math.gamma(n))*float(math.factorial(int(k[i]))))\n",
    "#     pt2 = (alpha/(alpha+math.exp(beta1*a[i]+beta2*b[i]+beta3*c[i]+beta4*d[i])))**n\n",
    "#     pt3 = (e**(beta1*a[i]+beta2*b[i]+beta3*c[i]+beta4*d[i])/(alpha+float((e**(beta1*a[i]+beta2*b[i]+beta3*c[i]+beta4*d[i])))))**k[i]\n",
    "#     p = p+np.log(pt1*pt2*pt3)\n",
    "# print(\"Alpha:{}\".format(alpha))\n",
    "# print(\"n:{}\".format(n))\n",
    "# print(\"Log likelihood:{}\".format(nbd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solnbdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solnbdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: For each of the models above, can you provide some managerial takeaways?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Analysis of New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Read books.csv and generate two new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('books.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) books01.csv, with the structure of the dataset used in the billboard exposures example (i.e., with only two columns – (i) the number purchases, and (ii) the number of people making the corresponding number of purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df['userid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.Series(df2.value_counts()).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df1['userid']\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books01 = df3.value_counts().to_frame()\n",
    "books01['no_of_purch']=books01.index\n",
    "books01.rename(columns = {'userid':'ppl_purchasing'}, inplace = True)\n",
    "books01=books01.reset_index(drop=True).sort_values('no_of_purch')\n",
    "books01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books01.to_csv('books01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books01=pd.read_csv('books01.csv')\n",
    "books01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) books02.csv, with the structure of the dataset used in the khakichinos.com example, with a new column containing a count of the number of books purchased from barnesandnoble.com by each customer, while keeping the demographic variables (remember to drop date, product, and price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=pd.read_csv('books.csv')\n",
    "# df5=df5[(df5 == 'barnesandnoble.com').any(axis=1)]\n",
    "df5.loc[df5[\"domain\"].isin([\"barnesandnoble.com\"]), \"domain\"]\n",
    "df5=df5.reset_index(drop=True)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df5[['userid','qty']]\n",
    "a=df6.groupby('userid').sum()\n",
    "a['userid']=a.index #a holds the qty by userid\n",
    "a.index.names = ['index']\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=df5.drop(['qty','price','product','date'], axis=1)\n",
    "b=df7.groupby('userid').mean()\n",
    "b['userid']=b.index\n",
    "b.index.names=['index']\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books02=pd.merge(a,b,on='userid')\n",
    "books02.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books02.to_csv('books02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books02=pd.read_csv('books02.csv')\n",
    "books02.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the first and last few records of both new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Develop a Poisson model using books01.csv. Report your code, the estimated parameters and the maximum value of the log-likelihood (and any other information you believe is relevant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=books01\n",
    "\n",
    "a = np.array(df[['ppl_purchasing']]) #define the first array that will go through the PLL function\n",
    "b = np.array(df[['no_of_purch']]) #define the second array that will go through PLL\n",
    "lmbda = 1\n",
    "\n",
    "def LL(lmbda,a,b):\n",
    "    c = 0 #we create a variable that will store the cummulative sum of the iteration below\n",
    "    for i in range(len(a)): #this will go through through the dataset rows\n",
    "        c += a[i]*np.log(poisson.pmf(b[i], lmbda)+1) #we get the sum of PEOPLE[i]*LN(POISSON(EXPOSURES[i],lambda))\n",
    "    return (-1)*c #we need the non-negative cummulative result so that we can maximize ll\n",
    "\n",
    "soln = minimize(\n",
    "    LL,\n",
    "    args = (a,b),\n",
    "    x0 = np.array((1)),\n",
    "    bounds=[(0.000001,None)],\n",
    "    ##tol=1e-10,\n",
    "    #options={'ftol' : 1e-8},\n",
    ")\n",
    "final_lmbda = soln.x[0]\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    c += a[i]*np.log(poisson.pmf(b[i],final_lmbda)+1)\n",
    "\n",
    "print(\"Lambda value for poisson model after optimzation {}\".format(final_lmbda))\n",
    "print(\"Log likelihood function value for poisson model after optimzation {}\".format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Develop a Poisson model using books02.csv, i.e., by ignoring the independent variables available. Report your code, and confirm that the estimated parameters and the maximum value of the log-likelihood are identical to those obtained with the Poisson model developed using books01.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_books=books02.drop(['education','region','hhsz','age','income','child','race','country'],axis=1)\n",
    "new_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=books02\n",
    "\n",
    "# a = np.array(df[['ppl_purchasing']]) #define the first array that will go through the PLL function\n",
    "# b = np.array(df[['no_of_purch']]) #define the second array that will go through PLL\n",
    "lmbda = 1\n",
    "\n",
    "def LL(lmbda,a,b):\n",
    "    c = 0 #we create a variable that will store the cummulative sum of the iteration below\n",
    "    for i in range(len(a)): #this will go through through the dataset rows\n",
    "        c += a[i]*np.log(poisson.pmf(b[i], lmbda)+1) #we get the sum of PEOPLE[i]*LN(POISSON(EXPOSURES[i],lambda))\n",
    "    return (-1)*c #we need the non-negative cummulative result so that we can maximize ll\n",
    "\n",
    "soln = minimize(\n",
    "    LL,\n",
    "    args = (a,b),\n",
    "    x0 = np.array((1)),\n",
    "    bounds=[(0.000001,None)],\n",
    "    ##tol=1e-10,\n",
    "    #options={'ftol' : 1e-8},\n",
    ")\n",
    "final_lmbda = soln.x[0]\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    c += a[i]*np.log(poisson.pmf(b[i],final_lmbda)+1)\n",
    "\n",
    "print(\"Lambda value for poisson model after optimzation {}\".format(final_lmbda))\n",
    "print(\"Log likelihood function value for poisson model after optimzation {}\".format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Develop an NBD model using books01.csv. Report your code, the estimated parameters and the maximum value of the log-likelihood (and any other information you believe is relevant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('books01.csv')\n",
    "\n",
    "def NBD(params,k,t):\n",
    "    alpha,n = params\n",
    "    if k==0:\n",
    "        return (alpha/(alpha+t))**n\n",
    "    else:\n",
    "        return (((n+k-1)*t)/(k*(alpha+t))) * NBD(params,k-1,t)\n",
    "\n",
    "\n",
    "def NBDLL(params,t,a,b):\n",
    "    nbd = 0\n",
    "    for i in range(len(a)):\n",
    "        nbd += a[i]*np.log(NBD(params,b[i],t))\n",
    "    return (-1)*nbd\n",
    "\n",
    "alpha = 1\n",
    "n = 1\n",
    "t = 1\n",
    "solnbd = minimize(\n",
    "    NBDLL,\n",
    "    args = (t,a,b),\n",
    "    x0 = np.array((1,1)),\n",
    "    bounds=[(0.000001,None),(0.000001,None)],\n",
    "    tol=1e-10,\n",
    "    options={'ftol' : 1e-8},\n",
    ")\n",
    "alpha = solnbd.x[0]\n",
    "n = solnbd.x[1]\n",
    "nbd = 0\n",
    "params = (alpha,n)\n",
    "for i in range(len(a)):\n",
    "    nbd += a[i]*np.log(NBD(params,b[i],t))\n",
    "\n",
    "print(\"Alpha:{}\".format(alpha))\n",
    "print(\"n:{}\".format(n))\n",
    "print(\"Log likelihood:{}\".format(nbd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Develop an NBD model using books02.csv (again, ignoring the variables available). Report your code, and confirm that the estimated parameters and the maximum value of the log-likelihood are identical to those obtained with the NBD model developed using books01.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('books02.csv')\n",
    "\n",
    "def NBD(params,k,t):\n",
    "    alpha,n = params\n",
    "    if k==0:\n",
    "        return (alpha/(alpha+t))**n\n",
    "    else:\n",
    "        return (((n+k-1)*t)/(k*(alpha+t))) * NBD(params,k-1,t)\n",
    "\n",
    "\n",
    "def NBDLL(params,t,a,b):\n",
    "    nbd = 0\n",
    "    for i in range(len(a)):\n",
    "        nbd += a[i]*np.log(NBD(params,b[i],t))\n",
    "    return (-1)*nbd\n",
    "\n",
    "alpha = 1\n",
    "n = 1\n",
    "t = 1\n",
    "solnbd = minimize(\n",
    "    NBDLL,\n",
    "    args = (t,a,b),\n",
    "    x0 = np.array((1,1)),\n",
    "    bounds=[(0.000001,None),(0.000001,None)],\n",
    "    tol=1e-10,\n",
    "    options={'ftol' : 1e-8},\n",
    ")\n",
    "alpha = solnbd.x[0]\n",
    "n = solnbd.x[1]\n",
    "t=solnbd.x[]\n",
    "nbd = 0\n",
    "params = (alpha,n)\n",
    "for i in range(len(a)):\n",
    "    nbd += a[i]*np.log(NBD(params,b[i],t))\n",
    "print(\"Alpha:{}\".format(alpha))\n",
    "print(\"n:{}\".format(n))\n",
    "print('t:{}'.format(t))\n",
    "print(\"Log likelihood:{}\".format(nbd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: Calculate the values of (i) reach, (ii) average frequency, and (iii) gross ratings points (GRPs) based on the NBD model. Show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reach (proportion of population who bought a book at least once at barnesandnobles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reach=100*(1-((alpha/(alpha+t))**n))\n",
    "reach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average frequency (average # of books purchased among those who bought a book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_frequency=n/alpha/(1-(alpha/(alpha+t)))\n",
    "avg_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gross ratings points (average # of books purchased per 100 people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grps=reach*avg_frequency\n",
    "grps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: Identify all independent variables with missing values. How many values are missing in each? Drop any variable with many missing values (specify how you are defining ‘many’). If the number of missing values are very few (again, specify how you are defining ‘few’), delete the rows involved. For the remaining variables (if any), replace the missing values with the means of the corresponding variables. Report your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books02=pd.read_csv('books02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(books02['education'].isna().sum())\n",
    "print(books02['region'].isna().sum())\n",
    "print(books02['hhsz'].isna().sum())\n",
    "print(books02['age'].isna().sum())\n",
    "print(books02['income'].isna().sum())\n",
    "print(books02['child'].isna().sum())\n",
    "print(books02['race'].isna().sum())\n",
    "print(books02['country'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books02=books02.drop(['education'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_region=books02['region'].mean()\n",
    "avg_age=books02['age'].mean()\n",
    "print(avg_region)\n",
    "print(avg_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books02['region']=books02['region'].fillna(avg_region)\n",
    "books02['age']=books02['age'].fillna(avg_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(books02['region'].isna().sum())\n",
    "print(books02['hhsz'].isna().sum())\n",
    "print(books02['age'].isna().sum())\n",
    "print(books02['income'].isna().sum())\n",
    "print(books02['child'].isna().sum())\n",
    "print(books02['race'].isna().sum())\n",
    "print(books02['country'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: Incorporate the available customer characteristics and estimate all relevant parameters for Poisson regression using MLE. Report your code, the estimated parameters and the maximum value of the log-likelihood (and any other information you believe is relevant). What are the managerial takeaways — which customer characteristics seem to be important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: Estimate all relevant parameters for NBD regression using MLE. Report your code, the estimated parameters and the maximum value of the log-likelihood (and any other information you believe is relevant). What are the managerial takeaways — which customer characteristics seem to be important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Evaluate all the models developed using the log-likelihood ratio, AIC, and BIC. What are your recommendations on which model to use based on each of these criteria? Are the recommendations consistent? Explain why you are recommending the model you have selected. Are there any significant differences among the results from the models? If so, what exactly are these differences? Discuss what you believe could be causing the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11: Briefly summarize what you learned from this project. This is an open-ended question, so please include anything you found worthwhile — relating to the modeling process, insights from the process and models, any managerial takeaways that were insightful to you, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
